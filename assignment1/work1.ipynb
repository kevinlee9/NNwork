{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# a simple MLP network\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "hidden_size=100\n",
    "output_size=3\n",
    "batch_size=50\n",
    "beta = 0.1 # regularization\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_dir = \"train_test\"\n",
    "    X_train = spio.loadmat(data_dir + \"/\" + \"train_data.mat\")[\"train_data\"]\n",
    "    X_test = spio.loadmat(data_dir + \"/\" + \"test_data.mat\")[\"test_data\"]\n",
    "    y_train = spio.loadmat(data_dir + \"/\" + \"train_label.mat\")[\"train_label\"]\n",
    "    y_test = spio.loadmat(data_dir + \"/\" + \"test_label.mat\")[\"test_label\"]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = X.mean(axis=0)\n",
    "    var = X.std(axis=0)\n",
    "    return (X - mean) / var, mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def visual_2D(X, y):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_r = pca.fit(X).transform(X)\n",
    "    \n",
    "    # plot \n",
    "    plt.figure()\n",
    "    colors = ['navy', 'turquoise', 'darkorange']\n",
    "    lw = 2\n",
    "    target_names = [\"-1\", \"0\", \"1\"]\n",
    "    for color, i, target_name in zip(colors, [-1, 0, 1], target_names):\n",
    "        plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,\n",
    "                    label=target_name)\n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title('PCA of Input dataset')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lb2vec(y_in):\n",
    "    y = y_in.ravel()\n",
    "    a = y - y.min()\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM6tTTgBmZnXq/wOvSVd4AH0dSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f00284c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train_lb, y_test_lb = load_data()\n",
    "\n",
    "X_train.dump(\"out/X_train.np\")\n",
    "X_test.dump(\"out/X_test.np\")\n",
    "y_train_lb.dump(\"out/y_train.np\")\n",
    "y_test_lb.dump(\"out/y_test.np\")\n",
    "\n",
    "# visualize original data in 2D\n",
    "visual_2D(np.vstack((X_train, X_test)),np.vstack((y_train_lb,y_test_lb)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_train_mean, X_train_var = normalize(X_train)\n",
    "# X_test = normalize(X_test)\n",
    "X_test = (X_test - X_train_mean) / X_train_var\n",
    "# map y labels to one-hot format\n",
    "y_train = lb2vec(y_train_lb)\n",
    "y_test = lb2vec(y_test_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MLP model\n",
    "def mlp_model(input_layer, hidden_size=hidden_size):\n",
    "    W1 = tf.Variable(tf.random_normal([310, hidden_size], mean=0.0, stddev=1.0))\n",
    "    b1 = tf.Variable(tf.random_normal([1, hidden_size], mean=0.0, stddev=1.0))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul(input_layer, W1) + b1)\n",
    "    W2 = tf.Variable(tf.random_normal([hidden_size, output_size], mean=0.0, stddev=1.0))\n",
    "    b2 = tf.Variable(tf.random_normal([1, output_size], mean=0.0, stddev=1.0))\n",
    "    output_layer = tf.matmul(hidden_layer, W2) + b2\n",
    "    \n",
    "    regularizer = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(b2)\n",
    "    return output_layer, regularizer\n",
    "\n",
    "# pipeline\n",
    "input_layer = tf.placeholder(tf.float32, shape=(None, 310))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, output_size))\n",
    "output_layer, regularizer = mlp_model(input_layer)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y_label)) + beta * regularizer\n",
    "\n",
    "# opt = tf.train.AdadeltaOptimizer(0.1)\n",
    "opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "y_predict = tf.nn.softmax(output_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict, axis=1), tf.argmax(y_label, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sess.run(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y_label), feed_dict={input_layer: X_train, y_label: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sess.run(b1, feed_dict={input_layer: X_test, y_label: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sess.run(loss, feed_dict={input_layer: X_test, y_label: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train, mini-batch processing\n",
    "def train():\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        rand_index = np.random.choice(len(X_train), size=batch_size)\n",
    "        rand_x = X_train[rand_index]\n",
    "        rand_y = y_train[rand_index]\n",
    "        train_dict = {input_layer: rand_x, y_label: rand_y}\n",
    "        test_dict = {input_layer: X_test, y_label: y_test}\n",
    "        sess.run(train_step, feed_dict=train_dict)\n",
    "        if (i+1)% 25 == 0:\n",
    "            print('Step #' + str(i+1))\n",
    "            print('Train loss = ' + str(sess.run(loss, feed_dict=train_dict)))\n",
    "            print('Test loss = ' + str(sess.run(loss, feed_dict=test_dict)))\n",
    "            print('Accuracy(Test) = ' + str(sess.run(accuracy, feed_dict=test_dict)))\n",
    "            \n",
    "    return float(sess.run(accuracy, feed_dict=test_dict))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Step #25\n",
      "Train loss = 1216.57\n",
      "Test loss = 1244.27\n",
      "Accuracy(Test) = 0.492711\n",
      "Step #50\n",
      "Train loss = 946.875\n",
      "Test loss = 968.41\n",
      "Accuracy(Test) = 0.492711\n",
      "Step #75\n",
      "Train loss = 736.963\n",
      "Test loss = 753.698\n",
      "Accuracy(Test) = 0.492711\n",
      "Step #100\n",
      "Train loss = 573.589\n",
      "Test loss = 586.593\n",
      "Accuracy(Test) = 0.492711\n",
      "Step #125\n",
      "Train loss = 446.431\n",
      "Test loss = 456.539\n",
      "Accuracy(Test) = 0.492711\n",
      "Step #150\n",
      "Train loss = 347.463\n",
      "Test loss = 355.319\n",
      "Accuracy(Test) = 0.492711\n",
      "Step #175\n",
      "Train loss = 270.436\n",
      "Test loss = 276.539\n",
      "Accuracy(Test) = 0.48688\n",
      "Step #200\n",
      "Train loss = 210.484\n",
      "Test loss = 215.223\n",
      "Accuracy(Test) = 0.38484\n",
      "Step #225\n",
      "Train loss = 163.823\n",
      "Test loss = 167.542\n",
      "Accuracy(Test) = 0.344023\n",
      "Step #250\n",
      "Train loss = 127.508\n",
      "Test loss = 130.477\n",
      "Accuracy(Test) = 0.51312\n",
      "Step #275\n",
      "Train loss = 99.2452\n",
      "Test loss = 101.641\n",
      "Accuracy(Test) = 0.51312\n",
      "Step #300\n",
      "Train loss = 77.2493\n",
      "Test loss = 79.1924\n",
      "Accuracy(Test) = 0.51312\n",
      "Step #325\n",
      "Train loss = 60.134\n",
      "Test loss = 61.7414\n",
      "Accuracy(Test) = 0.580175\n",
      "Step #350\n",
      "Train loss = 46.8151\n",
      "Test loss = 48.1673\n",
      "Accuracy(Test) = 0.766764\n",
      "Step #375\n",
      "Train loss = 36.4516\n",
      "Test loss = 37.62\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #400\n",
      "Train loss = 28.39\n",
      "Test loss = 29.4025\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #425\n",
      "Train loss = 22.1172\n",
      "Test loss = 23.0062\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.2368\n",
      "Test loss = 18.0512\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.4447\n",
      "Test loss = 14.1755\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.4906\n",
      "Test loss = 11.1987\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.19628\n",
      "Test loss = 8.87403\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.41136\n",
      "Test loss = 7.07524\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.02248\n",
      "Test loss = 5.67237\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.94589\n",
      "Test loss = 4.57424\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.10298\n",
      "Test loss = 3.72493\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.45099\n",
      "Test loss = 3.0659\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.94432\n",
      "Test loss = 2.55978\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.5462\n",
      "Test loss = 2.16374\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.23728\n",
      "Test loss = 1.8527\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 1.00056\n",
      "Test loss = 1.59877\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.810049\n",
      "Test loss = 1.41432\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.66755\n",
      "Test loss = 1.2571\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.551516\n",
      "Test loss = 1.14896\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.466414\n",
      "Test loss = 1.08323\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.399065\n",
      "Test loss = 0.989825\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.341023\n",
      "Test loss = 0.933795\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.304761\n",
      "Test loss = 0.877273\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.269608\n",
      "Test loss = 0.834234\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.242708\n",
      "Test loss = 0.81929\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.223053\n",
      "Test loss = 0.789512\n",
      "Accuracy(Test) = 0.830904\n",
      "1\n",
      "Step #25\n",
      "Train loss = 1220.8\n",
      "Test loss = 1226.36\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #50\n",
      "Train loss = 950.165\n",
      "Test loss = 954.48\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #75\n",
      "Train loss = 739.525\n",
      "Test loss = 742.872\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #100\n",
      "Train loss = 575.581\n",
      "Test loss = 578.173\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #125\n",
      "Train loss = 447.982\n",
      "Test loss = 449.985\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #150\n",
      "Train loss = 348.671\n",
      "Test loss = 350.211\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #175\n",
      "Train loss = 271.375\n",
      "Test loss = 272.553\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #200\n",
      "Train loss = 211.215\n",
      "Test loss = 212.113\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #225\n",
      "Train loss = 164.392\n",
      "Test loss = 165.088\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #250\n",
      "Train loss = 127.95\n",
      "Test loss = 128.568\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #275\n",
      "Train loss = 99.5884\n",
      "Test loss = 100.231\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #300\n",
      "Train loss = 77.5152\n",
      "Test loss = 78.2102\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #325\n",
      "Train loss = 60.3379\n",
      "Test loss = 61.0064\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #350\n",
      "Train loss = 46.9696\n",
      "Test loss = 47.6168\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #375\n",
      "Train loss = 36.5695\n",
      "Test loss = 37.2061\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #400\n",
      "Train loss = 28.4768\n",
      "Test loss = 29.1077\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #425\n",
      "Train loss = 22.1825\n",
      "Test loss = 22.7903\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.2866\n",
      "Test loss = 17.9088\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.48\n",
      "Test loss = 14.0929\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.519\n",
      "Test loss = 11.1232\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.21569\n",
      "Test loss = 8.80404\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.42831\n",
      "Test loss = 7.01418\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.03611\n",
      "Test loss = 5.61823\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.95328\n",
      "Test loss = 4.5454\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.10921\n",
      "Test loss = 3.67897\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.4557\n",
      "Test loss = 3.03987\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.94793\n",
      "Test loss = 2.50347\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.5461\n",
      "Test loss = 2.12913\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.24226\n",
      "Test loss = 1.80967\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 0.999174\n",
      "Test loss = 1.56809\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.812379\n",
      "Test loss = 1.38608\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.669292\n",
      "Test loss = 1.24279\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.554492\n",
      "Test loss = 1.11314\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.463645\n",
      "Test loss = 1.03941\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.395599\n",
      "Test loss = 0.972498\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.341743\n",
      "Test loss = 0.90322\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.299897\n",
      "Test loss = 0.856614\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.26692\n",
      "Test loss = 0.840381\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.24068\n",
      "Test loss = 0.813623\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.222565\n",
      "Test loss = 0.79734\n",
      "Accuracy(Test) = 0.830904\n",
      "2\n",
      "Step #25\n",
      "Train loss = 1227.39\n",
      "Test loss = 1248.4\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #50\n",
      "Train loss = 955.293\n",
      "Test loss = 971.634\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #75\n",
      "Train loss = 743.517\n",
      "Test loss = 756.229\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #100\n",
      "Train loss = 578.689\n",
      "Test loss = 588.577\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #125\n",
      "Train loss = 450.401\n",
      "Test loss = 458.097\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #150\n",
      "Train loss = 350.553\n",
      "Test loss = 356.546\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #175\n",
      "Train loss = 272.84\n",
      "Test loss = 277.513\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #200\n",
      "Train loss = 212.355\n",
      "Test loss = 216.003\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #225\n",
      "Train loss = 165.279\n",
      "Test loss = 168.131\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #250\n",
      "Train loss = 128.64\n",
      "Test loss = 130.864\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #275\n",
      "Train loss = 100.124\n",
      "Test loss = 101.823\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #300\n",
      "Train loss = 77.9295\n",
      "Test loss = 79.1976\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #325\n",
      "Train loss = 60.6587\n",
      "Test loss = 61.6097\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #350\n",
      "Train loss = 47.2179\n",
      "Test loss = 47.9762\n",
      "Accuracy(Test) = 0.661808\n",
      "Step #375\n",
      "Train loss = 36.7601\n",
      "Test loss = 37.4215\n",
      "Accuracy(Test) = 0.661808\n",
      "Step #400\n",
      "Train loss = 28.6246\n",
      "Test loss = 29.2537\n",
      "Accuracy(Test) = 0.661808\n",
      "Step #425\n",
      "Train loss = 22.2964\n",
      "Test loss = 22.9014\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.3767\n",
      "Test loss = 17.9697\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.5505\n",
      "Test loss = 14.1424\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.5722\n",
      "Test loss = 11.1618\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.25723\n",
      "Test loss = 8.84544\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.46116\n",
      "Test loss = 7.05283\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.06047\n",
      "Test loss = 5.65601\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.97151\n",
      "Test loss = 4.55678\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.12596\n",
      "Test loss = 3.71638\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.472\n",
      "Test loss = 3.06789\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.95744\n",
      "Test loss = 2.56255\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.55749\n",
      "Test loss = 2.1624\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.24883\n",
      "Test loss = 1.84356\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 1.0078\n",
      "Test loss = 1.61127\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.817602\n",
      "Test loss = 1.42623\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.66969\n",
      "Test loss = 1.27051\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.556688\n",
      "Test loss = 1.15027\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.465389\n",
      "Test loss = 1.04838\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.400781\n",
      "Test loss = 0.982418\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.343926\n",
      "Test loss = 0.930291\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.302819\n",
      "Test loss = 0.894138\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.271851\n",
      "Test loss = 0.862077\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.245269\n",
      "Test loss = 0.83859\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.226689\n",
      "Test loss = 0.813596\n",
      "Accuracy(Test) = 0.830904\n",
      "3\n",
      "Step #25\n",
      "Train loss = 1237.86\n",
      "Test loss = 1271.64\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #50\n",
      "Train loss = 963.444\n",
      "Test loss = 989.748\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #75\n",
      "Train loss = 749.861\n",
      "Test loss = 770.319\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #100\n",
      "Train loss = 583.626\n",
      "Test loss = 599.509\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #125\n",
      "Train loss = 454.244\n",
      "Test loss = 466.567\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #150\n",
      "Train loss = 353.545\n",
      "Test loss = 363.095\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #175\n",
      "Train loss = 275.169\n",
      "Test loss = 282.563\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #200\n",
      "Train loss = 214.167\n",
      "Test loss = 219.87\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #225\n",
      "Train loss = 166.691\n",
      "Test loss = 171.033\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #250\n",
      "Train loss = 129.739\n",
      "Test loss = 132.996\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #275\n",
      "Train loss = 100.98\n",
      "Test loss = 103.372\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #300\n",
      "Train loss = 78.5976\n",
      "Test loss = 80.3861\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #325\n",
      "Train loss = 61.1794\n",
      "Test loss = 62.5552\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #350\n",
      "Train loss = 47.6248\n",
      "Test loss = 48.7158\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #375\n",
      "Train loss = 37.0758\n",
      "Test loss = 37.9947\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #400\n",
      "Train loss = 28.8707\n",
      "Test loss = 29.6534\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #425\n",
      "Train loss = 22.4874\n",
      "Test loss = 23.1988\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #450\n",
      "Train loss = 17.5273\n",
      "Test loss = 18.2005\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #475\n",
      "Train loss = 13.6678\n",
      "Test loss = 14.3513\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #500\n",
      "Train loss = 10.6656\n",
      "Test loss = 11.2978\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #525\n",
      "Train loss = 8.33634\n",
      "Test loss = 8.95619\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.51675\n",
      "Test loss = 7.14585\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.10562\n",
      "Test loss = 5.72084\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 4.0083\n",
      "Test loss = 4.61449\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.15304\n",
      "Test loss = 3.76102\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.49199\n",
      "Test loss = 3.08932\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.97526\n",
      "Test loss = 2.57548\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.57102\n",
      "Test loss = 2.16828\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.25883\n",
      "Test loss = 1.84714\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 1.02002\n",
      "Test loss = 1.60746\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.827174\n",
      "Test loss = 1.40674\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.676696\n",
      "Test loss = 1.25766\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.562709\n",
      "Test loss = 1.1438\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.472665\n",
      "Test loss = 1.06126\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.39994\n",
      "Test loss = 0.975066\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.350665\n",
      "Test loss = 0.918604\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.305246\n",
      "Test loss = 0.881693\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.272726\n",
      "Test loss = 0.850891\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.242065\n",
      "Test loss = 0.832694\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.223503\n",
      "Test loss = 0.818745\n",
      "Accuracy(Test) = 0.830904\n",
      "4\n",
      "Step #25\n",
      "Train loss = 1210.89\n",
      "Test loss = 1242.82\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #50\n",
      "Train loss = 942.453\n",
      "Test loss = 967.295\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #75\n",
      "Train loss = 733.522\n",
      "Test loss = 752.763\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #100\n",
      "Train loss = 570.911\n",
      "Test loss = 585.781\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #125\n",
      "Train loss = 444.347\n",
      "Test loss = 455.834\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #150\n",
      "Train loss = 345.841\n",
      "Test loss = 354.805\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #175\n",
      "Train loss = 269.174\n",
      "Test loss = 276.189\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #200\n",
      "Train loss = 209.502\n",
      "Test loss = 214.998\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #225\n",
      "Train loss = 163.06\n",
      "Test loss = 167.409\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #250\n",
      "Train loss = 126.913\n",
      "Test loss = 130.315\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #275\n",
      "Train loss = 98.782\n",
      "Test loss = 101.483\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #300\n",
      "Train loss = 76.887\n",
      "Test loss = 79.0316\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #325\n",
      "Train loss = 59.8492\n",
      "Test loss = 61.631\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #350\n",
      "Train loss = 46.5911\n",
      "Test loss = 48.0443\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #375\n",
      "Train loss = 36.2745\n",
      "Test loss = 37.5237\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #400\n",
      "Train loss = 28.2498\n",
      "Test loss = 29.3429\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #425\n",
      "Train loss = 22.0076\n",
      "Test loss = 22.9847\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.1503\n",
      "Test loss = 18.0424\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.373\n",
      "Test loss = 14.2069\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.4363\n",
      "Test loss = 11.2056\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.15491\n",
      "Test loss = 8.89716\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.37899\n",
      "Test loss = 7.07969\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 4.99443\n",
      "Test loss = 5.68018\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.92162\n",
      "Test loss = 4.59309\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.08544\n",
      "Test loss = 3.73899\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.4379\n",
      "Test loss = 3.07052\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.93296\n",
      "Test loss = 2.55314\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.53587\n",
      "Test loss = 2.14484\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.22846\n",
      "Test loss = 1.8329\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 0.993348\n",
      "Test loss = 1.58894\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.806458\n",
      "Test loss = 1.41254\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.661452\n",
      "Test loss = 1.2571\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.548816\n",
      "Test loss = 1.13116\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.462875\n",
      "Test loss = 1.02727\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.391782\n",
      "Test loss = 0.958745\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.341052\n",
      "Test loss = 0.9073\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.297124\n",
      "Test loss = 0.859407\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.26708\n",
      "Test loss = 0.820516\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.242171\n",
      "Test loss = 0.812771\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.221963\n",
      "Test loss = 0.782714\n",
      "Accuracy(Test) = 0.830904\n",
      "5\n",
      "Step #25\n",
      "Train loss = 1241.62\n",
      "Test loss = 1293.79\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #50\n",
      "Train loss = 966.365\n",
      "Test loss = 1006.93\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #75\n",
      "Train loss = 752.135\n",
      "Test loss = 783.669\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #100\n",
      "Train loss = 585.396\n",
      "Test loss = 609.907\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #125\n",
      "Train loss = 455.621\n",
      "Test loss = 474.67\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #150\n",
      "Train loss = 354.616\n",
      "Test loss = 369.418\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #175\n",
      "Train loss = 276.003\n",
      "Test loss = 287.503\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #200\n",
      "Train loss = 214.817\n",
      "Test loss = 223.76\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #225\n",
      "Train loss = 167.197\n",
      "Test loss = 174.16\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #250\n",
      "Train loss = 130.132\n",
      "Test loss = 135.561\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #275\n",
      "Train loss = 101.286\n",
      "Test loss = 105.532\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #300\n",
      "Train loss = 78.8351\n",
      "Test loss = 82.1934\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #325\n",
      "Train loss = 61.3631\n",
      "Test loss = 64.0277\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #350\n",
      "Train loss = 47.7669\n",
      "Test loss = 49.9103\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #375\n",
      "Train loss = 37.1847\n",
      "Test loss = 38.867\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #400\n",
      "Train loss = 28.9541\n",
      "Test loss = 30.3136\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #425\n",
      "Train loss = 22.5521\n",
      "Test loss = 23.7241\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #450\n",
      "Train loss = 17.5755\n",
      "Test loss = 18.6058\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #475\n",
      "Train loss = 13.7024\n",
      "Test loss = 14.6355\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #500\n",
      "Train loss = 10.6966\n",
      "Test loss = 11.5374\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #525\n",
      "Train loss = 8.3577\n",
      "Test loss = 9.15106\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.53751\n",
      "Test loss = 7.30319\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.1211\n",
      "Test loss = 5.83997\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 4.02146\n",
      "Test loss = 4.70016\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.16289\n",
      "Test loss = 3.8142\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.49765\n",
      "Test loss = 3.12567\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.9809\n",
      "Test loss = 2.5947\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.57575\n",
      "Test loss = 2.18328\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.25967\n",
      "Test loss = 1.89234\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 1.02093\n",
      "Test loss = 1.62615\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.829564\n",
      "Test loss = 1.42281\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.680107\n",
      "Test loss = 1.26646\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.564659\n",
      "Test loss = 1.16116\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.474238\n",
      "Test loss = 1.05297\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.402157\n",
      "Test loss = 0.999925\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.349208\n",
      "Test loss = 0.939187\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.304884\n",
      "Test loss = 0.895688\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.273531\n",
      "Test loss = 0.859689\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.247091\n",
      "Test loss = 0.825006\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.225134\n",
      "Test loss = 0.803039\n",
      "Accuracy(Test) = 0.830904\n",
      "6\n",
      "Step #25\n",
      "Train loss = 1216.32\n",
      "Test loss = 1249.13\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #50\n",
      "Train loss = 946.679\n",
      "Test loss = 972.219\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #75\n",
      "Train loss = 736.811\n",
      "Test loss = 756.696\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #100\n",
      "Train loss = 573.469\n",
      "Test loss = 588.937\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #125\n",
      "Train loss = 446.339\n",
      "Test loss = 458.335\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #150\n",
      "Train loss = 347.392\n",
      "Test loss = 356.657\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #175\n",
      "Train loss = 270.38\n",
      "Test loss = 277.498\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #200\n",
      "Train loss = 210.441\n",
      "Test loss = 215.889\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #225\n",
      "Train loss = 163.79\n",
      "Test loss = 167.941\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #250\n",
      "Train loss = 127.482\n",
      "Test loss = 130.63\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #275\n",
      "Train loss = 99.224\n",
      "Test loss = 101.615\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #300\n",
      "Train loss = 77.2328\n",
      "Test loss = 79.088\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #325\n",
      "Train loss = 60.1168\n",
      "Test loss = 61.6151\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #350\n",
      "Train loss = 46.7989\n",
      "Test loss = 48.0115\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #375\n",
      "Train loss = 36.4389\n",
      "Test loss = 37.4692\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #400\n",
      "Train loss = 28.376\n",
      "Test loss = 29.2738\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #425\n",
      "Train loss = 22.1064\n",
      "Test loss = 22.9155\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.2294\n",
      "Test loss = 17.9851\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.436\n",
      "Test loss = 14.1552\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.4829\n",
      "Test loss = 11.1593\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.19044\n",
      "Test loss = 8.85952\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.40747\n",
      "Test loss = 7.02674\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.0202\n",
      "Test loss = 5.64087\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.93822\n",
      "Test loss = 4.54185\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.10251\n",
      "Test loss = 3.68237\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.44994\n",
      "Test loss = 3.03646\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.94115\n",
      "Test loss = 2.53074\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.54694\n",
      "Test loss = 2.13974\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.23924\n",
      "Test loss = 1.81715\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 0.998756\n",
      "Test loss = 1.58097\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.813521\n",
      "Test loss = 1.39152\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.665607\n",
      "Test loss = 1.27166\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.553325\n",
      "Test loss = 1.13472\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.46268\n",
      "Test loss = 1.04103\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.394249\n",
      "Test loss = 0.976631\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.339215\n",
      "Test loss = 0.920687\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.299835\n",
      "Test loss = 0.88225\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.267475\n",
      "Test loss = 0.840306\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.245861\n",
      "Test loss = 0.818807\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.223539\n",
      "Test loss = 0.793044\n",
      "Accuracy(Test) = 0.830904\n",
      "7\n",
      "Step #25\n",
      "Train loss = 1226.18\n",
      "Test loss = 1238.87\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #50\n",
      "Train loss = 954.348\n",
      "Test loss = 964.221\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #75\n",
      "Train loss = 742.781\n",
      "Test loss = 750.462\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #100\n",
      "Train loss = 578.116\n",
      "Test loss = 584.071\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #125\n",
      "Train loss = 449.955\n",
      "Test loss = 454.476\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #150\n",
      "Train loss = 350.206\n",
      "Test loss = 353.567\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #175\n",
      "Train loss = 272.57\n",
      "Test loss = 275.011\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #200\n",
      "Train loss = 212.145\n",
      "Test loss = 213.929\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #225\n",
      "Train loss = 165.116\n",
      "Test loss = 166.435\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #250\n",
      "Train loss = 128.513\n",
      "Test loss = 129.519\n",
      "Accuracy(Test) = 0.661808\n",
      "Step #275\n",
      "Train loss = 100.025\n",
      "Test loss = 100.83\n",
      "Accuracy(Test) = 0.661808\n",
      "Step #300\n",
      "Train loss = 77.8545\n",
      "Test loss = 78.5621\n",
      "Accuracy(Test) = 0.661808\n",
      "Step #325\n",
      "Train loss = 60.6002\n",
      "Test loss = 61.2262\n",
      "Accuracy(Test) = 0.708455\n",
      "Step #350\n",
      "Train loss = 47.1728\n",
      "Test loss = 47.7539\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #375\n",
      "Train loss = 36.7265\n",
      "Test loss = 37.3048\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #400\n",
      "Train loss = 28.6024\n",
      "Test loss = 29.1664\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #425\n",
      "Train loss = 22.2818\n",
      "Test loss = 22.8472\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.3667\n",
      "Test loss = 17.9214\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.5417\n",
      "Test loss = 14.0926\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.5706\n",
      "Test loss = 11.1194\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.25795\n",
      "Test loss = 8.80219\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.45962\n",
      "Test loss = 7.0139\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.06091\n",
      "Test loss = 5.61987\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.97386\n",
      "Test loss = 4.53197\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.12967\n",
      "Test loss = 3.69546\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.46753\n",
      "Test loss = 3.02824\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.95839\n",
      "Test loss = 2.51603\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.5567\n",
      "Test loss = 2.13064\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.2434\n",
      "Test loss = 1.8135\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 1.00551\n",
      "Test loss = 1.56418\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.818264\n",
      "Test loss = 1.37745\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.672239\n",
      "Test loss = 1.24545\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.554314\n",
      "Test loss = 1.13291\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.467532\n",
      "Test loss = 1.02935\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.398607\n",
      "Test loss = 0.966683\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.348133\n",
      "Test loss = 0.893417\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.302943\n",
      "Test loss = 0.849377\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.261802\n",
      "Test loss = 0.835889\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.243277\n",
      "Test loss = 0.803086\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.227002\n",
      "Test loss = 0.775523\n",
      "Accuracy(Test) = 0.830904\n",
      "8\n",
      "Step #25\n",
      "Train loss = 1204.28\n",
      "Test loss = 1248.31\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #50\n",
      "Train loss = 937.304\n",
      "Test loss = 971.563\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #75\n",
      "Train loss = 729.515\n",
      "Test loss = 756.166\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #100\n",
      "Train loss = 567.792\n",
      "Test loss = 588.523\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #125\n",
      "Train loss = 441.919\n",
      "Test loss = 458.044\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #150\n",
      "Train loss = 343.951\n",
      "Test loss = 356.492\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #175\n",
      "Train loss = 267.701\n",
      "Test loss = 277.454\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #200\n",
      "Train loss = 208.355\n",
      "Test loss = 215.939\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #225\n",
      "Train loss = 162.166\n",
      "Test loss = 168.057\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #250\n",
      "Train loss = 126.216\n",
      "Test loss = 130.766\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #275\n",
      "Train loss = 98.2358\n",
      "Test loss = 101.647\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #300\n",
      "Train loss = 76.4596\n",
      "Test loss = 78.9954\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #325\n",
      "Train loss = 59.5132\n",
      "Test loss = 61.3912\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #350\n",
      "Train loss = 46.3267\n",
      "Test loss = 47.8096\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #375\n",
      "Train loss = 36.0667\n",
      "Test loss = 37.2528\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #400\n",
      "Train loss = 28.0832\n",
      "Test loss = 29.0379\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #425\n",
      "Train loss = 21.8761\n",
      "Test loss = 22.6906\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #450\n",
      "Train loss = 17.0467\n",
      "Test loss = 17.7942\n",
      "Accuracy(Test) = 0.682216\n",
      "Step #475\n",
      "Train loss = 13.2922\n",
      "Test loss = 13.988\n",
      "Accuracy(Test) = 0.696793\n",
      "Step #500\n",
      "Train loss = 10.3749\n",
      "Test loss = 11.0195\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.10559\n",
      "Test loss = 8.73388\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.33719\n",
      "Test loss = 6.98019\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 4.96835\n",
      "Test loss = 5.58815\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.90324\n",
      "Test loss = 4.49834\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.071\n",
      "Test loss = 3.65791\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.42587\n",
      "Test loss = 3.0226\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.92374\n",
      "Test loss = 2.52961\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.53194\n",
      "Test loss = 2.13184\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.22956\n",
      "Test loss = 1.81332\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 0.987814\n",
      "Test loss = 1.57128\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.805027\n",
      "Test loss = 1.39301\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.662455\n",
      "Test loss = 1.24352\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.551443\n",
      "Test loss = 1.12442\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.46048\n",
      "Test loss = 1.03392\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.394752\n",
      "Test loss = 0.950023\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.340636\n",
      "Test loss = 0.919537\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.30048\n",
      "Test loss = 0.882847\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.268117\n",
      "Test loss = 0.833733\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.239746\n",
      "Test loss = 0.809547\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.223226\n",
      "Test loss = 0.782444\n",
      "Accuracy(Test) = 0.830904\n",
      "9\n",
      "Step #25\n",
      "Train loss = 1220.24\n",
      "Test loss = 1228.79\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #50\n",
      "Train loss = 949.729\n",
      "Test loss = 956.385\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #75\n",
      "Train loss = 739.185\n",
      "Test loss = 744.366\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #100\n",
      "Train loss = 575.317\n",
      "Test loss = 579.347\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #125\n",
      "Train loss = 447.776\n",
      "Test loss = 450.889\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #150\n",
      "Train loss = 348.51\n",
      "Test loss = 350.866\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #175\n",
      "Train loss = 271.251\n",
      "Test loss = 272.96\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #200\n",
      "Train loss = 211.118\n",
      "Test loss = 212.288\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #225\n",
      "Train loss = 164.318\n",
      "Test loss = 165.075\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #250\n",
      "Train loss = 127.892\n",
      "Test loss = 128.356\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #275\n",
      "Train loss = 99.5442\n",
      "Test loss = 99.7902\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #300\n",
      "Train loss = 77.4814\n",
      "Test loss = 77.6383\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #325\n",
      "Train loss = 60.3119\n",
      "Test loss = 60.4738\n",
      "Accuracy(Test) = 1.0\n",
      "Step #350\n",
      "Train loss = 46.9513\n",
      "Test loss = 47.1967\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #375\n",
      "Train loss = 36.5564\n",
      "Test loss = 36.8611\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #400\n",
      "Train loss = 28.4714\n",
      "Test loss = 28.8295\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #425\n",
      "Train loss = 22.1822\n",
      "Test loss = 22.5704\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #450\n",
      "Train loss = 17.2888\n",
      "Test loss = 17.6987\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #475\n",
      "Train loss = 13.4861\n",
      "Test loss = 13.918\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #500\n",
      "Train loss = 10.5282\n",
      "Test loss = 11.0092\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #525\n",
      "Train loss = 8.22309\n",
      "Test loss = 8.73331\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #550\n",
      "Train loss = 6.43372\n",
      "Test loss = 6.97262\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #575\n",
      "Train loss = 5.0471\n",
      "Test loss = 5.58429\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #600\n",
      "Train loss = 3.9611\n",
      "Test loss = 4.5205\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #625\n",
      "Train loss = 3.11786\n",
      "Test loss = 3.68829\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #650\n",
      "Train loss = 2.46421\n",
      "Test loss = 3.02845\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #675\n",
      "Train loss = 1.95498\n",
      "Test loss = 2.53139\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #700\n",
      "Train loss = 1.55365\n",
      "Test loss = 2.13401\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #725\n",
      "Train loss = 1.24736\n",
      "Test loss = 1.81901\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #750\n",
      "Train loss = 1.00243\n",
      "Test loss = 1.59476\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #775\n",
      "Train loss = 0.815867\n",
      "Test loss = 1.3917\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #800\n",
      "Train loss = 0.670904\n",
      "Test loss = 1.22995\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #825\n",
      "Train loss = 0.55674\n",
      "Test loss = 1.11897\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #850\n",
      "Train loss = 0.468199\n",
      "Test loss = 1.03115\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #875\n",
      "Train loss = 0.396468\n",
      "Test loss = 0.961606\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #900\n",
      "Train loss = 0.340384\n",
      "Test loss = 0.919183\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #925\n",
      "Train loss = 0.303815\n",
      "Test loss = 0.868304\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #950\n",
      "Train loss = 0.272077\n",
      "Test loss = 0.83739\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #975\n",
      "Train loss = 0.249343\n",
      "Test loss = 0.815263\n",
      "Accuracy(Test) = 0.830904\n",
      "Step #1000\n",
      "Train loss = 0.228662\n",
      "Test loss = 0.787815\n",
      "Accuracy(Test) = 0.830904\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "time_list = []\n",
    "\n",
    "for iters in range(10):\n",
    "    print iters\n",
    "    start_time = time.time()\n",
    "    loss_list.append(train())\n",
    "    end_time = time.time()\n",
    "    time_list.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on test set(hidden_size=100):  0.830903768539\n"
     ]
    }
   ],
   "source": [
    "print \"Average accuracy on test set(hidden_size=100): \", sum(loss_list) / len(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Average accuracy on test set(hidden_size=10): \", sum(loss_list) / len(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Average accuracy on test set(hidden_size=1): \", sum(loss_list) / len(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time cost:  2.24938123226\n"
     ]
    }
   ],
   "source": [
    "print \"Average time cost: \", sum(time_list) / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
